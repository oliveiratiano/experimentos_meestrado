{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import transformer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "df = pd.read_csv(\"dados/corpus_tratado/metadados.csv\")[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando os ids por assuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corte = 50\n",
    "df_validos = pd.DataFrame(df.groupby(\"Assunto\").size()).reset_index()\n",
    "df_validos.columns = [\"assunto\", \"quant\"]\n",
    "df_validos = df_validos.loc[df_validos.quant >= corte]\n",
    "display(df_validos.quant.sum())\n",
    "display(df_validos.assunto.nunique())\n",
    "documentos_validos = df[df.Assunto.isin(df_validos.assunto)][[\"id\", \"Assunto\"]].reset_index().drop('index', axis = 1)\n",
    "diretorio = \"dados/corpus_tratado/\"\n",
    "documentos_validos['arquivo'] = documentos_validos.id + '.txt'\n",
    "documentos_validos['teores'] = [transformer.recuperar_teor(x, diretorio) for x in tqdm(documentos_validos['arquivo'])]\n",
    "documentos_validos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cortando documentos curtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_palavras_documento = 50\n",
    "documentos_validos['validos'] = documentos_validos.teores.apply(lambda x: 0 if len(x.split(' ')) <= min_palavras_documento else 1)\n",
    "documentos_validos = documentos_validos[documentos_validos['validos'] == 1].drop(['arquivo', 'teores', 'validos'], axis = 1).reset_index().drop('index', axis = 1)\n",
    "documentos_validos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execução do fluxo de experimentação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_experimentos = 1\n",
    "lista_k = np.arange(2,10)\n",
    "grid_minfreqs = [0, 50, 100]\n",
    "grid_stopwords = [True, False]\n",
    "grid_ica = [True, False]\n",
    "grid_tesauro = [True, False]\n",
    "grid_dimensoes = [100,300]\n",
    "df = transformer.transform_param(documentos_validos, n_experimentos, grid_minfreqs, grid_stopwords, grid_ica, grid_tesauro, grid_dimensoes, lista_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "lista_k = [2, 3, 4]\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "dir_experimento = 'experimento___minfreq_0__com_crit_tesauro__com_crit_ica__removeu_sw_pt__100_dims__1'\n",
    "le = LabelEncoder()\n",
    "modelo = 'vec_w2v_ger_soma'\n",
    "df = pd.read_csv('dados/'+dir_experimento+'/vetores_teste.csv')\n",
    "df[modelo] = df[modelo].apply(lambda x: transformer.converter_string_array(x))\n",
    "X_kmeans = np.stack(df[modelo])\n",
    "X_kmeans = X_kmeans.reshape(X_kmeans.shape[0], X_kmeans.shape[2])\n",
    "y_kmeans = df['assunto']\n",
    "le.fit(y_kmeans)\n",
    "y_kmeans = le.transform(y_kmeans)\n",
    "lista_scores_k = transformer.computar_scores_agrupamento(X_kmeans, y_kmeans, dir_experimento, modelo, lista_k)\n",
    "transformer.gerar_graficos_kmeans(lista_scores_k, dir_experimento, modelo)\n",
    "np.save(dir_experimento + '/lista_scores_k.npy', lista_scores_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kmeans = np.stack(df[modelo])\n",
    "X_kmeans = X_kmeans.reshape(X_kmeans.shape[0], X_kmeans.shape[2])\n",
    "X_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[modelo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

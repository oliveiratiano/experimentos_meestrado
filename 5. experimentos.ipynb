{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import grouper\n",
    "import pandas as pd\n",
    "import nltk\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "df = pd.read_csv(\"dados/corpus_tratado/metadados.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando os ids por assuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35027"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Assunto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1500075-43.2019.8.26.0569</td>\n",
       "      <td>Tráfico de Drogas e Condutas Afins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1019468-32.2019.8.26.0562</td>\n",
       "      <td>Alienação Fiduciária</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000043-68.2019.8.26.0616</td>\n",
       "      <td>Furto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1007259-02.2018.8.26.0292</td>\n",
       "      <td>DIREITO PREVIDENCIÁRIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000425-53.2019.8.26.0128</td>\n",
       "      <td>Rural (Art. 48/51)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35022</td>\n",
       "      <td>0001233-88.2018.8.26.0426</td>\n",
       "      <td>Cheque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35023</td>\n",
       "      <td>1514316-66.2019.8.26.0037</td>\n",
       "      <td>Impostos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35024</td>\n",
       "      <td>1008737-24.2019.8.26.0320</td>\n",
       "      <td>Indenização por Dano Material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35025</td>\n",
       "      <td>0000206-22.2019.8.26.0075</td>\n",
       "      <td>IPTU/ Imposto Predial e Territorial Urbano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35026</td>\n",
       "      <td>1002580-07.2019.8.26.0297</td>\n",
       "      <td>Indenização por Dano Moral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35027 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id                                     Assunto\n",
       "0      1500075-43.2019.8.26.0569          Tráfico de Drogas e Condutas Afins\n",
       "1      1019468-32.2019.8.26.0562                        Alienação Fiduciária\n",
       "2      0000043-68.2019.8.26.0616                                       Furto\n",
       "3      1007259-02.2018.8.26.0292                      DIREITO PREVIDENCIÁRIO\n",
       "4      1000425-53.2019.8.26.0128                          Rural (Art. 48/51)\n",
       "...                          ...                                         ...\n",
       "35022  0001233-88.2018.8.26.0426                                      Cheque\n",
       "35023  1514316-66.2019.8.26.0037                                    Impostos\n",
       "35024  1008737-24.2019.8.26.0320               Indenização por Dano Material\n",
       "35025  0000206-22.2019.8.26.0075  IPTU/ Imposto Predial e Territorial Urbano\n",
       "35026  1002580-07.2019.8.26.0297                  Indenização por Dano Moral\n",
       "\n",
       "[35027 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corte = 50\n",
    "df_validos = pd.DataFrame(df.groupby(\"Assunto\").size()).reset_index()\n",
    "df_validos.columns = [\"assunto\", \"quant\"]\n",
    "df_validos = df_validos.loc[df_validos.quant >= corte]\n",
    "display(df_validos.quant.sum())\n",
    "display(df_validos.assunto.nunique())\n",
    "documentos_validos = df[df.Assunto.isin(df_validos.assunto)][[\"id\", \"Assunto\"]].reset_index().drop('index', axis = 1)\n",
    "documentos_validos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando grupos de treino e teste de maneira que as distribuições de assuntos permaneçam similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "X = documentos_validos.id\n",
    "y = documentos_validos.Assunto\n",
    "caminho_corpus = \"dados/corpus_tratado/\"\n",
    "\n",
    "#index[0] são os indices de treino, e index[1] são os de teste\n",
    "#i é o código do experimento\n",
    "for i, index in enumerate(sss.split(X, y)):    \n",
    "    exp = i+1\n",
    "    X_treino, X_teste = X[index[0]], X[index[1]]\n",
    "    y_treino, y_teste = y[index[0]], y[index[1]]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando o corpus do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criando base de treino para o experimento 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c382e41a26e4c569c823a574c76afeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "16042036 tokens copiados com sucesso\n",
      "preparando documentos para extração do vocabulário:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c832b63708d40b4886a0a48682434e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=28021), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28021, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "diretorio = \"dados/corpus_tratado/\"\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "X_treino = pd.DataFrame(X_treino)\n",
    "X_treino['id'] = X_treino.id + '.txt'\n",
    "\n",
    "print(\"criando base de treino para o experimento \"+str(exp))\n",
    "if not os.path.exists('dados/experimento_'+str(exp)):\n",
    "    os.makedirs('dados/experimento_'+str(exp))\n",
    "\n",
    "#a base de treino para o word2vec e fasttext deve ter uma frase por linha\n",
    "#a base de treino para o glove deve ter um documento por linha\n",
    "base_treino = open('dados/experimento_'+str(exp)+'/base_treino.txt', 'w+', encoding='utf8')\n",
    "base_treino_glv = open('dados/experimento_'+str(exp)+'/base_treino_glv.txt', 'w+', encoding='utf8')\n",
    "tokens = 0\n",
    "for documento in tqdm(X_treino.id.values):\n",
    "    doc = open(diretorio + documento, 'r', encoding='utf8')\n",
    "    for frase in doc:\n",
    "        base_treino.write(frase)\n",
    "        tokens += len(frase.split(\" \"))\n",
    "    doc.close()\n",
    "    \n",
    "    doc = open(diretorio + documento, 'r', encoding='utf8')\n",
    "    teor_completo = doc.read().replace('\\n', '')\n",
    "    teor_completo = grouper.remover_stopwords(teor_completo, stopwords)\n",
    "    base_treino_glv.write(teor_completo + '\\n')\n",
    "    doc.close()\n",
    "    \n",
    "base_treino.close()\n",
    "base_treino_glv.close()\n",
    "print(str(tokens)+ \" tokens copiados com sucesso\")\n",
    "print(\"preparando documentos para extração do vocabulário:\")\n",
    "X_treino['teores'] = [grouper.recuperar_teor(x, diretorio) for x in tqdm(X_treino.id)]\n",
    "X_treino['assunto'] = y_treino\n",
    "X_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extraindo termos com base no ICA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 314.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-processando strings do corpus\n",
      "-treinando vetorizador\n",
      "-ICA processado\n",
      "extraindo termos com base na frequência - geralmente leva menos de 4 minutos\n",
      "extraindo termos do tesauro\n",
      "extração de vocabulário concluída!\n"
     ]
    }
   ],
   "source": [
    "freq_min = 100\n",
    "vocab = grouper.extrair_vocabulario(X_treino, freq_min, stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando modelo word2vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:01:30,015 : INFO : collecting all words and their counts\n",
      "2021-02-24 00:01:30,021 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-24 00:01:30,090 : INFO : PROGRESS: at sentence #10000, processed 235769 words, keeping 13479 word types\n",
      "2021-02-24 00:01:30,162 : INFO : PROGRESS: at sentence #20000, processed 478506 words, keeping 18827 word types\n",
      "2021-02-24 00:01:30,234 : INFO : PROGRESS: at sentence #30000, processed 716990 words, keeping 22433 word types\n",
      "2021-02-24 00:01:30,304 : INFO : PROGRESS: at sentence #40000, processed 956912 words, keeping 25453 word types\n",
      "2021-02-24 00:01:30,374 : INFO : PROGRESS: at sentence #50000, processed 1198453 words, keeping 27868 word types\n",
      "2021-02-24 00:01:30,444 : INFO : PROGRESS: at sentence #60000, processed 1434600 words, keeping 30340 word types\n",
      "2021-02-24 00:01:30,515 : INFO : PROGRESS: at sentence #70000, processed 1678430 words, keeping 32461 word types\n",
      "2021-02-24 00:01:30,585 : INFO : PROGRESS: at sentence #80000, processed 1918098 words, keeping 34310 word types\n",
      "2021-02-24 00:01:30,652 : INFO : PROGRESS: at sentence #90000, processed 2156336 words, keeping 36035 word types\n",
      "2021-02-24 00:01:30,721 : INFO : PROGRESS: at sentence #100000, processed 2398940 words, keeping 37617 word types\n",
      "2021-02-24 00:01:30,788 : INFO : PROGRESS: at sentence #110000, processed 2637175 words, keeping 39115 word types\n",
      "2021-02-24 00:01:30,856 : INFO : PROGRESS: at sentence #120000, processed 2877198 words, keeping 40535 word types\n",
      "2021-02-24 00:01:30,924 : INFO : PROGRESS: at sentence #130000, processed 3116326 words, keeping 41914 word types\n",
      "2021-02-24 00:01:30,994 : INFO : PROGRESS: at sentence #140000, processed 3366816 words, keeping 43473 word types\n",
      "2021-02-24 00:01:31,067 : INFO : PROGRESS: at sentence #150000, processed 3614701 words, keeping 44786 word types\n",
      "2021-02-24 00:01:31,134 : INFO : PROGRESS: at sentence #160000, processed 3855422 words, keeping 46007 word types\n",
      "2021-02-24 00:01:31,204 : INFO : PROGRESS: at sentence #170000, processed 4094891 words, keeping 47124 word types\n",
      "2021-02-24 00:01:31,274 : INFO : PROGRESS: at sentence #180000, processed 4334237 words, keeping 48340 word types\n",
      "2021-02-24 00:01:31,342 : INFO : PROGRESS: at sentence #190000, processed 4576252 words, keeping 49342 word types\n",
      "2021-02-24 00:01:31,414 : INFO : PROGRESS: at sentence #200000, processed 4824132 words, keeping 50480 word types\n",
      "2021-02-24 00:01:31,480 : INFO : PROGRESS: at sentence #210000, processed 5062126 words, keeping 51483 word types\n",
      "2021-02-24 00:01:31,549 : INFO : PROGRESS: at sentence #220000, processed 5305266 words, keeping 52429 word types\n",
      "2021-02-24 00:01:31,617 : INFO : PROGRESS: at sentence #230000, processed 5550723 words, keeping 53444 word types\n",
      "2021-02-24 00:01:31,687 : INFO : PROGRESS: at sentence #240000, processed 5800318 words, keeping 54412 word types\n",
      "2021-02-24 00:01:31,757 : INFO : PROGRESS: at sentence #250000, processed 6049857 words, keeping 55457 word types\n",
      "2021-02-24 00:01:31,825 : INFO : PROGRESS: at sentence #260000, processed 6288867 words, keeping 56253 word types\n",
      "2021-02-24 00:01:31,897 : INFO : PROGRESS: at sentence #270000, processed 6539964 words, keeping 57133 word types\n",
      "2021-02-24 00:01:31,966 : INFO : PROGRESS: at sentence #280000, processed 6783410 words, keeping 57987 word types\n",
      "2021-02-24 00:01:32,038 : INFO : PROGRESS: at sentence #290000, processed 7025570 words, keeping 58857 word types\n",
      "2021-02-24 00:01:32,108 : INFO : PROGRESS: at sentence #300000, processed 7272182 words, keeping 59616 word types\n",
      "2021-02-24 00:01:32,178 : INFO : PROGRESS: at sentence #310000, processed 7515122 words, keeping 60294 word types\n",
      "2021-02-24 00:01:32,247 : INFO : PROGRESS: at sentence #320000, processed 7760803 words, keeping 61115 word types\n",
      "2021-02-24 00:01:32,316 : INFO : PROGRESS: at sentence #330000, processed 8007403 words, keeping 61972 word types\n",
      "2021-02-24 00:01:32,390 : INFO : PROGRESS: at sentence #340000, processed 8245032 words, keeping 62740 word types\n",
      "2021-02-24 00:01:32,460 : INFO : PROGRESS: at sentence #350000, processed 8486427 words, keeping 63495 word types\n",
      "2021-02-24 00:01:32,531 : INFO : PROGRESS: at sentence #360000, processed 8726848 words, keeping 64225 word types\n",
      "2021-02-24 00:01:32,599 : INFO : PROGRESS: at sentence #370000, processed 8973299 words, keeping 64913 word types\n",
      "2021-02-24 00:01:32,674 : INFO : PROGRESS: at sentence #380000, processed 9213292 words, keeping 65645 word types\n",
      "2021-02-24 00:01:32,748 : INFO : PROGRESS: at sentence #390000, processed 9460659 words, keeping 66427 word types\n",
      "2021-02-24 00:01:32,818 : INFO : PROGRESS: at sentence #400000, processed 9704171 words, keeping 67037 word types\n",
      "2021-02-24 00:01:32,887 : INFO : PROGRESS: at sentence #410000, processed 9944273 words, keeping 67717 word types\n",
      "2021-02-24 00:01:32,956 : INFO : PROGRESS: at sentence #420000, processed 10186493 words, keeping 68483 word types\n",
      "2021-02-24 00:01:33,026 : INFO : PROGRESS: at sentence #430000, processed 10430824 words, keeping 69260 word types\n",
      "2021-02-24 00:01:33,096 : INFO : PROGRESS: at sentence #440000, processed 10675104 words, keeping 69962 word types\n",
      "2021-02-24 00:01:33,168 : INFO : PROGRESS: at sentence #450000, processed 10916543 words, keeping 70624 word types\n",
      "2021-02-24 00:01:33,238 : INFO : PROGRESS: at sentence #460000, processed 11153599 words, keeping 71178 word types\n",
      "2021-02-24 00:01:33,310 : INFO : PROGRESS: at sentence #470000, processed 11400246 words, keeping 71873 word types\n",
      "2021-02-24 00:01:33,378 : INFO : PROGRESS: at sentence #480000, processed 11641081 words, keeping 72449 word types\n",
      "2021-02-24 00:01:33,447 : INFO : PROGRESS: at sentence #490000, processed 11879460 words, keeping 73023 word types\n",
      "2021-02-24 00:01:33,518 : INFO : PROGRESS: at sentence #500000, processed 12122776 words, keeping 73581 word types\n",
      "2021-02-24 00:01:33,586 : INFO : PROGRESS: at sentence #510000, processed 12367121 words, keeping 74255 word types\n",
      "2021-02-24 00:01:33,655 : INFO : PROGRESS: at sentence #520000, processed 12607611 words, keeping 74782 word types\n",
      "2021-02-24 00:01:33,726 : INFO : PROGRESS: at sentence #530000, processed 12851530 words, keeping 75319 word types\n",
      "2021-02-24 00:01:33,800 : INFO : PROGRESS: at sentence #540000, processed 13089923 words, keeping 75959 word types\n",
      "2021-02-24 00:01:33,868 : INFO : PROGRESS: at sentence #550000, processed 13327324 words, keeping 76489 word types\n",
      "2021-02-24 00:01:33,941 : INFO : PROGRESS: at sentence #560000, processed 13575962 words, keeping 77031 word types\n",
      "2021-02-24 00:01:34,008 : INFO : PROGRESS: at sentence #570000, processed 13817112 words, keeping 77602 word types\n",
      "2021-02-24 00:01:34,076 : INFO : PROGRESS: at sentence #580000, processed 14052857 words, keeping 78189 word types\n",
      "2021-02-24 00:01:34,148 : INFO : PROGRESS: at sentence #590000, processed 14300517 words, keeping 78737 word types\n",
      "2021-02-24 00:01:34,219 : INFO : PROGRESS: at sentence #600000, processed 14545068 words, keeping 79300 word types\n",
      "2021-02-24 00:01:34,289 : INFO : PROGRESS: at sentence #610000, processed 14792482 words, keeping 79812 word types\n",
      "2021-02-24 00:01:34,362 : INFO : PROGRESS: at sentence #620000, processed 15030477 words, keeping 80319 word types\n",
      "2021-02-24 00:01:34,437 : INFO : PROGRESS: at sentence #630000, processed 15269440 words, keeping 80955 word types\n",
      "2021-02-24 00:01:34,474 : INFO : collected 81218 word types from a corpus of 15387847 raw words and 634862 sentences\n",
      "2021-02-24 00:01:34,475 : INFO : Loading a fresh vocabulary\n",
      "2021-02-24 00:01:34,532 : INFO : effective_min_count=5 retains 32596 unique words (40% of original 81218, drops 48622)\n",
      "2021-02-24 00:01:34,533 : INFO : effective_min_count=5 leaves 15306026 word corpus (99% of original 15387847, drops 81821)\n",
      "2021-02-24 00:01:34,616 : INFO : deleting the raw counts dictionary of 81218 items\n",
      "2021-02-24 00:01:34,619 : INFO : sample=1e-05 downsamples 3206 most-common words\n",
      "2021-02-24 00:01:34,620 : INFO : downsampling leaves estimated 3697094 word corpus (24.2% of prior 15306026)\n",
      "2021-02-24 00:01:34,642 : INFO : constructing a huffman tree from 32596 words\n",
      "2021-02-24 00:01:35,337 : INFO : built huffman tree with maximum node depth 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:01:35,392 : INFO : estimated required memory for 32596 words and 100 dimensions: 61932400 bytes\n",
      "2021-02-24 00:01:35,393 : INFO : resetting layer weights\n",
      "2021-02-24 00:01:35,711 : INFO : training model with 12 workers on 32596 vocabulary and 100 features, using sg=1 hs=1 sample=1e-05 negative=5 window=5\n",
      "2021-02-24 00:01:36,722 : INFO : EPOCH 1 - PROGRESS: at 9.26% examples, 334972 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:37,728 : INFO : EPOCH 1 - PROGRESS: at 18.28% examples, 331639 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:01:38,730 : INFO : EPOCH 1 - PROGRESS: at 25.69% examples, 313549 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:39,732 : INFO : EPOCH 1 - PROGRESS: at 34.17% examples, 312994 words/s, in_qsize 2, out_qsize 0\n",
      "2021-02-24 00:01:40,734 : INFO : EPOCH 1 - PROGRESS: at 41.63% examples, 306512 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:41,735 : INFO : EPOCH 1 - PROGRESS: at 48.81% examples, 300297 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:01:42,734 : INFO : EPOCH 1 - PROGRESS: at 57.94% examples, 305550 words/s, in_qsize 10, out_qsize 1\n",
      "2021-02-24 00:01:43,748 : INFO : EPOCH 1 - PROGRESS: at 65.66% examples, 302544 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:44,750 : INFO : EPOCH 1 - PROGRESS: at 73.73% examples, 302229 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:01:45,763 : INFO : EPOCH 1 - PROGRESS: at 82.45% examples, 303628 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:46,768 : INFO : EPOCH 1 - PROGRESS: at 90.49% examples, 302620 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:01:47,772 : INFO : EPOCH 1 - PROGRESS: at 98.55% examples, 302228 words/s, in_qsize 3, out_qsize 2\n",
      "2021-02-24 00:01:47,853 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:01:47,855 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:01:47,857 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:01:47,858 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:01:47,876 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:01:47,879 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:01:47,882 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:01:47,884 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:01:47,891 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:01:47,898 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:01:47,903 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:01:47,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:01:47,907 : INFO : EPOCH - 1 : training on 15387847 raw words (3698355 effective words) took 12.2s, 303424 effective words/s\n",
      "2021-02-24 00:01:48,912 : INFO : EPOCH 2 - PROGRESS: at 8.59% examples, 312602 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:49,920 : INFO : EPOCH 2 - PROGRESS: at 16.30% examples, 296023 words/s, in_qsize 6, out_qsize 2\n",
      "2021-02-24 00:01:50,947 : INFO : EPOCH 2 - PROGRESS: at 25.24% examples, 305523 words/s, in_qsize 19, out_qsize 1\n",
      "2021-02-24 00:01:51,968 : INFO : EPOCH 2 - PROGRESS: at 33.65% examples, 304871 words/s, in_qsize 16, out_qsize 0\n",
      "2021-02-24 00:01:52,970 : INFO : EPOCH 2 - PROGRESS: at 41.43% examples, 302521 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:53,971 : INFO : EPOCH 2 - PROGRESS: at 49.32% examples, 301182 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:01:54,981 : INFO : EPOCH 2 - PROGRESS: at 56.87% examples, 297500 words/s, in_qsize 8, out_qsize 1\n",
      "2021-02-24 00:01:55,984 : INFO : EPOCH 2 - PROGRESS: at 65.28% examples, 299077 words/s, in_qsize 17, out_qsize 2\n",
      "2021-02-24 00:01:56,987 : INFO : EPOCH 2 - PROGRESS: at 74.31% examples, 303122 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:01:57,988 : INFO : EPOCH 2 - PROGRESS: at 81.87% examples, 300476 words/s, in_qsize 22, out_qsize 1\n",
      "2021-02-24 00:01:58,993 : INFO : EPOCH 2 - PROGRESS: at 90.89% examples, 302993 words/s, in_qsize 2, out_qsize 0\n",
      "2021-02-24 00:01:59,997 : INFO : EPOCH 2 - PROGRESS: at 99.43% examples, 303951 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:00,029 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:02:00,031 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:02:00,033 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:02:00,035 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:02:00,037 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:02:00,038 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:02:00,040 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:02:00,041 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:02:00,042 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:02:00,055 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:02:00,059 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:02:00,063 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:02:00,065 : INFO : EPOCH - 2 : training on 15387847 raw words (3696167 effective words) took 12.2s, 304113 effective words/s\n",
      "2021-02-24 00:02:01,072 : INFO : EPOCH 3 - PROGRESS: at 8.40% examples, 303852 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:02,136 : INFO : EPOCH 3 - PROGRESS: at 16.17% examples, 285228 words/s, in_qsize 23, out_qsize 1\n",
      "2021-02-24 00:02:03,136 : INFO : EPOCH 3 - PROGRESS: at 25.30% examples, 302874 words/s, in_qsize 0, out_qsize 2\n",
      "2021-02-24 00:02:04,143 : INFO : EPOCH 3 - PROGRESS: at 34.04% examples, 307061 words/s, in_qsize 1, out_qsize 1\n",
      "2021-02-24 00:02:05,143 : INFO : EPOCH 3 - PROGRESS: at 41.89% examples, 304773 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 00:02:06,147 : INFO : EPOCH 3 - PROGRESS: at 50.24% examples, 305724 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:02:07,147 : INFO : EPOCH 3 - PROGRESS: at 59.37% examples, 310162 words/s, in_qsize 0, out_qsize 2\n",
      "2021-02-24 00:02:08,158 : INFO : EPOCH 3 - PROGRESS: at 67.12% examples, 307224 words/s, in_qsize 23, out_qsize 1\n",
      "2021-02-24 00:02:09,190 : INFO : EPOCH 3 - PROGRESS: at 75.77% examples, 307454 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:02:10,192 : INFO : EPOCH 3 - PROGRESS: at 85.19% examples, 311119 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:02:11,201 : INFO : EPOCH 3 - PROGRESS: at 93.97% examples, 311963 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:11,795 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:02:11,797 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:02:11,802 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:02:11,815 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:02:11,819 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:02:11,825 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:02:11,827 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:02:11,831 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:02:11,835 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:02:11,837 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:02:11,840 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:02:11,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:02:11,843 : INFO : EPOCH - 3 : training on 15387847 raw words (3696236 effective words) took 11.8s, 313956 effective words/s\n",
      "2021-02-24 00:02:12,864 : INFO : EPOCH 4 - PROGRESS: at 8.47% examples, 303305 words/s, in_qsize 1, out_qsize 2\n",
      "2021-02-24 00:02:13,866 : INFO : EPOCH 4 - PROGRESS: at 17.36% examples, 314144 words/s, in_qsize 21, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:02:14,880 : INFO : EPOCH 4 - PROGRESS: at 26.82% examples, 324842 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:02:15,886 : INFO : EPOCH 4 - PROGRESS: at 35.06% examples, 319651 words/s, in_qsize 19, out_qsize 0\n",
      "2021-02-24 00:02:16,894 : INFO : EPOCH 4 - PROGRESS: at 44.05% examples, 323155 words/s, in_qsize 16, out_qsize 1\n",
      "2021-02-24 00:02:17,899 : INFO : EPOCH 4 - PROGRESS: at 53.54% examples, 327532 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:18,903 : INFO : EPOCH 4 - PROGRESS: at 61.88% examples, 324696 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:19,903 : INFO : EPOCH 4 - PROGRESS: at 70.03% examples, 322143 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 00:02:20,909 : INFO : EPOCH 4 - PROGRESS: at 78.64% examples, 321106 words/s, in_qsize 0, out_qsize 2\n",
      "2021-02-24 00:02:21,926 : INFO : EPOCH 4 - PROGRESS: at 87.02% examples, 319208 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:22,932 : INFO : EPOCH 4 - PROGRESS: at 95.56% examples, 318792 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:23,385 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:02:23,412 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:02:23,422 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:02:23,431 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:02:23,437 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:02:23,439 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:02:23,444 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:02:23,446 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:02:23,449 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:02:23,450 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:02:23,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:02:23,453 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:02:23,454 : INFO : EPOCH - 4 : training on 15387847 raw words (3697732 effective words) took 11.6s, 318603 effective words/s\n",
      "2021-02-24 00:02:24,460 : INFO : EPOCH 5 - PROGRESS: at 7.74% examples, 281349 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:02:25,466 : INFO : EPOCH 5 - PROGRESS: at 17.64% examples, 320543 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:26,470 : INFO : EPOCH 5 - PROGRESS: at 26.20% examples, 320102 words/s, in_qsize 21, out_qsize 0\n",
      "2021-02-24 00:02:27,477 : INFO : EPOCH 5 - PROGRESS: at 34.74% examples, 318063 words/s, in_qsize 22, out_qsize 0\n",
      "2021-02-24 00:02:28,477 : INFO : EPOCH 5 - PROGRESS: at 44.05% examples, 324912 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:29,484 : INFO : EPOCH 5 - PROGRESS: at 52.86% examples, 325067 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:30,488 : INFO : EPOCH 5 - PROGRESS: at 61.88% examples, 325953 words/s, in_qsize 13, out_qsize 1\n",
      "2021-02-24 00:02:31,503 : INFO : EPOCH 5 - PROGRESS: at 71.47% examples, 328954 words/s, in_qsize 2, out_qsize 0\n",
      "2021-02-24 00:02:32,509 : INFO : EPOCH 5 - PROGRESS: at 80.17% examples, 327951 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:33,517 : INFO : EPOCH 5 - PROGRESS: at 88.86% examples, 326608 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:02:34,535 : INFO : EPOCH 5 - PROGRESS: at 98.27% examples, 328075 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:34,699 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:02:34,701 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:02:34,702 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:02:34,703 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:02:34,705 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:02:34,707 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:02:34,708 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:02:34,710 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:02:34,715 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:02:34,723 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:02:34,738 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:02:34,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:02:34,744 : INFO : EPOCH - 5 : training on 15387847 raw words (3698479 effective words) took 11.3s, 327744 effective words/s\n",
      "2021-02-24 00:02:35,774 : INFO : EPOCH 6 - PROGRESS: at 8.27% examples, 292967 words/s, in_qsize 13, out_qsize 1\n",
      "2021-02-24 00:02:36,777 : INFO : EPOCH 6 - PROGRESS: at 17.70% examples, 318653 words/s, in_qsize 14, out_qsize 1\n",
      "2021-02-24 00:02:37,804 : INFO : EPOCH 6 - PROGRESS: at 26.40% examples, 317723 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:02:38,812 : INFO : EPOCH 6 - PROGRESS: at 36.27% examples, 328749 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:39,815 : INFO : EPOCH 6 - PROGRESS: at 44.32% examples, 323673 words/s, in_qsize 19, out_qsize 0\n",
      "2021-02-24 00:02:40,816 : INFO : EPOCH 6 - PROGRESS: at 53.33% examples, 325487 words/s, in_qsize 5, out_qsize 0\n",
      "2021-02-24 00:02:41,818 : INFO : EPOCH 6 - PROGRESS: at 62.77% examples, 328644 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:42,820 : INFO : EPOCH 6 - PROGRESS: at 71.08% examples, 326097 words/s, in_qsize 17, out_qsize 0\n",
      "2021-02-24 00:02:43,824 : INFO : EPOCH 6 - PROGRESS: at 79.98% examples, 326246 words/s, in_qsize 17, out_qsize 0\n",
      "2021-02-24 00:02:44,830 : INFO : EPOCH 6 - PROGRESS: at 88.80% examples, 325647 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:02:45,836 : INFO : EPOCH 6 - PROGRESS: at 96.60% examples, 322148 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:46,209 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:02:46,212 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:02:46,214 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:02:46,216 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:02:46,224 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:02:46,235 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:02:46,241 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:02:46,246 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:02:46,250 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:02:46,253 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:02:46,262 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:02:46,267 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:02:46,268 : INFO : EPOCH - 6 : training on 15387847 raw words (3698670 effective words) took 11.5s, 321084 effective words/s\n",
      "2021-02-24 00:02:47,281 : INFO : EPOCH 7 - PROGRESS: at 7.67% examples, 277128 words/s, in_qsize 3, out_qsize 1\n",
      "2021-02-24 00:02:48,282 : INFO : EPOCH 7 - PROGRESS: at 16.11% examples, 293034 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:49,286 : INFO : EPOCH 7 - PROGRESS: at 24.12% examples, 294809 words/s, in_qsize 0, out_qsize 3\n",
      "2021-02-24 00:02:50,287 : INFO : EPOCH 7 - PROGRESS: at 33.20% examples, 304425 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:51,293 : INFO : EPOCH 7 - PROGRESS: at 41.83% examples, 307875 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:02:52,300 : INFO : EPOCH 7 - PROGRESS: at 50.49% examples, 310127 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:53,306 : INFO : EPOCH 7 - PROGRESS: at 59.63% examples, 313681 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:54,307 : INFO : EPOCH 7 - PROGRESS: at 67.64% examples, 311843 words/s, in_qsize 21, out_qsize 1\n",
      "2021-02-24 00:02:55,319 : INFO : EPOCH 7 - PROGRESS: at 76.67% examples, 313868 words/s, in_qsize 16, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:02:56,326 : INFO : EPOCH 7 - PROGRESS: at 86.53% examples, 318069 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:57,329 : INFO : EPOCH 7 - PROGRESS: at 94.72% examples, 316954 words/s, in_qsize 15, out_qsize 1\n",
      "2021-02-24 00:02:57,808 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:02:57,815 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:02:57,816 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:02:57,817 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:02:57,820 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:02:57,821 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:02:57,822 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:02:57,823 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:02:57,832 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:02:57,845 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:02:57,855 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:02:57,856 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:02:57,856 : INFO : EPOCH - 7 : training on 15387847 raw words (3698459 effective words) took 11.6s, 319317 effective words/s\n",
      "2021-02-24 00:02:58,864 : INFO : EPOCH 8 - PROGRESS: at 8.80% examples, 318718 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:02:59,870 : INFO : EPOCH 8 - PROGRESS: at 17.04% examples, 309510 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:03:00,876 : INFO : EPOCH 8 - PROGRESS: at 25.61% examples, 312317 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:01,879 : INFO : EPOCH 8 - PROGRESS: at 33.97% examples, 310832 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:03:02,891 : INFO : EPOCH 8 - PROGRESS: at 42.77% examples, 314391 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:03:03,892 : INFO : EPOCH 8 - PROGRESS: at 51.81% examples, 318207 words/s, in_qsize 14, out_qsize 0\n",
      "2021-02-24 00:03:04,899 : INFO : EPOCH 8 - PROGRESS: at 61.23% examples, 322014 words/s, in_qsize 0, out_qsize 2\n",
      "2021-02-24 00:03:05,906 : INFO : EPOCH 8 - PROGRESS: at 70.23% examples, 323195 words/s, in_qsize 5, out_qsize 0\n",
      "2021-02-24 00:03:06,912 : INFO : EPOCH 8 - PROGRESS: at 78.44% examples, 320583 words/s, in_qsize 0, out_qsize 2\n",
      "2021-02-24 00:03:07,921 : INFO : EPOCH 8 - PROGRESS: at 87.63% examples, 321935 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:03:08,924 : INFO : EPOCH 8 - PROGRESS: at 96.74% examples, 323096 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:09,255 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:03:09,264 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:03:09,266 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:03:09,267 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:03:09,271 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:03:09,277 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:03:09,279 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:03:09,284 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:03:09,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:03:09,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:03:09,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:03:09,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:03:09,309 : INFO : EPOCH - 8 : training on 15387847 raw words (3695863 effective words) took 11.4s, 322853 effective words/s\n",
      "2021-02-24 00:03:10,323 : INFO : EPOCH 9 - PROGRESS: at 8.14% examples, 293694 words/s, in_qsize 18, out_qsize 0\n",
      "2021-02-24 00:03:11,326 : INFO : EPOCH 9 - PROGRESS: at 17.97% examples, 326299 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:03:12,330 : INFO : EPOCH 9 - PROGRESS: at 26.75% examples, 326198 words/s, in_qsize 0, out_qsize 2\n",
      "2021-02-24 00:03:13,344 : INFO : EPOCH 9 - PROGRESS: at 35.69% examples, 326569 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 00:03:14,349 : INFO : EPOCH 9 - PROGRESS: at 44.06% examples, 324126 words/s, in_qsize 18, out_qsize 1\n",
      "2021-02-24 00:03:15,383 : INFO : EPOCH 9 - PROGRESS: at 53.45% examples, 326390 words/s, in_qsize 22, out_qsize 1\n",
      "2021-02-24 00:03:16,405 : INFO : EPOCH 9 - PROGRESS: at 62.71% examples, 327563 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:17,416 : INFO : EPOCH 9 - PROGRESS: at 71.28% examples, 325782 words/s, in_qsize 0, out_qsize 1\n",
      "2021-02-24 00:03:18,416 : INFO : EPOCH 9 - PROGRESS: at 79.29% examples, 322339 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:03:19,423 : INFO : EPOCH 9 - PROGRESS: at 88.45% examples, 323483 words/s, in_qsize 15, out_qsize 4\n",
      "2021-02-24 00:03:20,435 : INFO : EPOCH 9 - PROGRESS: at 98.15% examples, 326251 words/s, in_qsize 1, out_qsize 0\n",
      "2021-02-24 00:03:20,575 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:03:20,594 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:03:20,601 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:03:20,603 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:03:20,604 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:03:20,610 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:03:20,615 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:03:20,632 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:03:20,636 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:03:20,641 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:03:20,646 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:03:20,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:03:20,648 : INFO : EPOCH - 9 : training on 15387847 raw words (3697493 effective words) took 11.3s, 326239 effective words/s\n",
      "2021-02-24 00:03:21,657 : INFO : EPOCH 10 - PROGRESS: at 8.14% examples, 294714 words/s, in_qsize 16, out_qsize 1\n",
      "2021-02-24 00:03:22,662 : INFO : EPOCH 10 - PROGRESS: at 17.24% examples, 313051 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:23,665 : INFO : EPOCH 10 - PROGRESS: at 26.14% examples, 319225 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:24,671 : INFO : EPOCH 10 - PROGRESS: at 34.49% examples, 315725 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:03:25,729 : INFO : EPOCH 10 - PROGRESS: at 43.49% examples, 316843 words/s, in_qsize 13, out_qsize 2\n",
      "2021-02-24 00:03:26,751 : INFO : EPOCH 10 - PROGRESS: at 53.07% examples, 322409 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:27,750 : INFO : EPOCH 10 - PROGRESS: at 62.37% examples, 325403 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:28,753 : INFO : EPOCH 10 - PROGRESS: at 71.54% examples, 326900 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:29,760 : INFO : EPOCH 10 - PROGRESS: at 79.46% examples, 322899 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:03:30,772 : INFO : EPOCH 10 - PROGRESS: at 89.37% examples, 326457 words/s, in_qsize 0, out_qsize 0\n",
      "2021-02-24 00:03:31,772 : INFO : EPOCH 10 - PROGRESS: at 97.76% examples, 324981 words/s, in_qsize 23, out_qsize 0\n",
      "2021-02-24 00:03:31,908 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:03:31,909 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:03:31,911 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:03:31,913 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:03:31,923 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:03:31,926 : INFO : worker thread finished; awaiting finish of 6 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:03:31,928 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:03:31,930 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:03:31,934 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:03:31,940 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:03:31,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:03:31,952 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:03:31,953 : INFO : EPOCH - 10 : training on 15387847 raw words (3697305 effective words) took 11.3s, 327196 effective words/s\n",
      "2021-02-24 00:03:31,955 : INFO : training on a 153878470 raw words (36974759 effective words) took 116.2s, 318084 effective words/s\n",
      "2021-02-24 00:03:31,956 : INFO : saving Word2Vec object under dados/experimento_1/w2v_jur.model, separately None\n",
      "2021-02-24 00:03:31,957 : INFO : not storing attribute vectors_norm\n",
      "2021-02-24 00:03:31,958 : INFO : not storing attribute cum_table\n",
      "2021-02-24 00:03:32,874 : INFO : saved dados/experimento_1/w2v_jur.model\n"
     ]
    }
   ],
   "source": [
    "w2v_jur = grouper.treinar_word2vec('dados/experimento_'+str(exp)+'/base_treino.txt', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando modelo word2vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:03:32,952 : INFO : resetting layer weights\n",
      "2021-02-24 00:03:37,921 : INFO : collecting all words and their counts\n",
      "2021-02-24 00:03:37,922 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-24 00:03:37,990 : INFO : PROGRESS: at sentence #10000, processed 235769 words, keeping 13479 word types\n",
      "2021-02-24 00:03:38,061 : INFO : PROGRESS: at sentence #20000, processed 478506 words, keeping 18827 word types\n",
      "2021-02-24 00:03:38,133 : INFO : PROGRESS: at sentence #30000, processed 716990 words, keeping 22433 word types\n",
      "2021-02-24 00:03:38,209 : INFO : PROGRESS: at sentence #40000, processed 956912 words, keeping 25453 word types\n",
      "2021-02-24 00:03:38,279 : INFO : PROGRESS: at sentence #50000, processed 1198453 words, keeping 27868 word types\n",
      "2021-02-24 00:03:38,350 : INFO : PROGRESS: at sentence #60000, processed 1434600 words, keeping 30340 word types\n",
      "2021-02-24 00:03:38,421 : INFO : PROGRESS: at sentence #70000, processed 1678430 words, keeping 32461 word types\n",
      "2021-02-24 00:03:38,490 : INFO : PROGRESS: at sentence #80000, processed 1918098 words, keeping 34310 word types\n",
      "2021-02-24 00:03:38,560 : INFO : PROGRESS: at sentence #90000, processed 2156336 words, keeping 36035 word types\n",
      "2021-02-24 00:03:38,629 : INFO : PROGRESS: at sentence #100000, processed 2398940 words, keeping 37617 word types\n",
      "2021-02-24 00:03:38,697 : INFO : PROGRESS: at sentence #110000, processed 2637175 words, keeping 39115 word types\n",
      "2021-02-24 00:03:38,767 : INFO : PROGRESS: at sentence #120000, processed 2877198 words, keeping 40535 word types\n",
      "2021-02-24 00:03:38,834 : INFO : PROGRESS: at sentence #130000, processed 3116326 words, keeping 41914 word types\n",
      "2021-02-24 00:03:38,906 : INFO : PROGRESS: at sentence #140000, processed 3366816 words, keeping 43473 word types\n",
      "2021-02-24 00:03:38,979 : INFO : PROGRESS: at sentence #150000, processed 3614701 words, keeping 44786 word types\n",
      "2021-02-24 00:03:39,050 : INFO : PROGRESS: at sentence #160000, processed 3855422 words, keeping 46007 word types\n",
      "2021-02-24 00:03:39,121 : INFO : PROGRESS: at sentence #170000, processed 4094891 words, keeping 47124 word types\n",
      "2021-02-24 00:03:39,192 : INFO : PROGRESS: at sentence #180000, processed 4334237 words, keeping 48340 word types\n",
      "2021-02-24 00:03:39,260 : INFO : PROGRESS: at sentence #190000, processed 4576252 words, keeping 49342 word types\n",
      "2021-02-24 00:03:39,330 : INFO : PROGRESS: at sentence #200000, processed 4824132 words, keeping 50480 word types\n",
      "2021-02-24 00:03:39,398 : INFO : PROGRESS: at sentence #210000, processed 5062126 words, keeping 51483 word types\n",
      "2021-02-24 00:03:39,467 : INFO : PROGRESS: at sentence #220000, processed 5305266 words, keeping 52429 word types\n",
      "2021-02-24 00:03:39,539 : INFO : PROGRESS: at sentence #230000, processed 5550723 words, keeping 53444 word types\n",
      "2021-02-24 00:03:39,612 : INFO : PROGRESS: at sentence #240000, processed 5800318 words, keeping 54412 word types\n",
      "2021-02-24 00:03:39,683 : INFO : PROGRESS: at sentence #250000, processed 6049857 words, keeping 55457 word types\n",
      "2021-02-24 00:03:39,751 : INFO : PROGRESS: at sentence #260000, processed 6288867 words, keeping 56253 word types\n",
      "2021-02-24 00:03:39,824 : INFO : PROGRESS: at sentence #270000, processed 6539964 words, keeping 57133 word types\n",
      "2021-02-24 00:03:39,894 : INFO : PROGRESS: at sentence #280000, processed 6783410 words, keeping 57987 word types\n",
      "2021-02-24 00:03:39,967 : INFO : PROGRESS: at sentence #290000, processed 7025570 words, keeping 58857 word types\n",
      "2021-02-24 00:03:40,045 : INFO : PROGRESS: at sentence #300000, processed 7272182 words, keeping 59616 word types\n",
      "2021-02-24 00:03:40,121 : INFO : PROGRESS: at sentence #310000, processed 7515122 words, keeping 60294 word types\n",
      "2021-02-24 00:03:40,198 : INFO : PROGRESS: at sentence #320000, processed 7760803 words, keeping 61115 word types\n",
      "2021-02-24 00:03:40,271 : INFO : PROGRESS: at sentence #330000, processed 8007403 words, keeping 61972 word types\n",
      "2021-02-24 00:03:40,339 : INFO : PROGRESS: at sentence #340000, processed 8245032 words, keeping 62740 word types\n",
      "2021-02-24 00:03:40,410 : INFO : PROGRESS: at sentence #350000, processed 8486427 words, keeping 63495 word types\n",
      "2021-02-24 00:03:40,480 : INFO : PROGRESS: at sentence #360000, processed 8726848 words, keeping 64225 word types\n",
      "2021-02-24 00:03:40,550 : INFO : PROGRESS: at sentence #370000, processed 8973299 words, keeping 64913 word types\n",
      "2021-02-24 00:03:40,623 : INFO : PROGRESS: at sentence #380000, processed 9213292 words, keeping 65645 word types\n",
      "2021-02-24 00:03:40,705 : INFO : PROGRESS: at sentence #390000, processed 9460659 words, keeping 66427 word types\n",
      "2021-02-24 00:03:40,777 : INFO : PROGRESS: at sentence #400000, processed 9704171 words, keeping 67037 word types\n",
      "2021-02-24 00:03:40,846 : INFO : PROGRESS: at sentence #410000, processed 9944273 words, keeping 67717 word types\n",
      "2021-02-24 00:03:40,915 : INFO : PROGRESS: at sentence #420000, processed 10186493 words, keeping 68483 word types\n",
      "2021-02-24 00:03:40,990 : INFO : PROGRESS: at sentence #430000, processed 10430824 words, keeping 69260 word types\n",
      "2021-02-24 00:03:41,061 : INFO : PROGRESS: at sentence #440000, processed 10675104 words, keeping 69962 word types\n",
      "2021-02-24 00:03:41,132 : INFO : PROGRESS: at sentence #450000, processed 10916543 words, keeping 70624 word types\n",
      "2021-02-24 00:03:41,201 : INFO : PROGRESS: at sentence #460000, processed 11153599 words, keeping 71178 word types\n",
      "2021-02-24 00:03:41,270 : INFO : PROGRESS: at sentence #470000, processed 11400246 words, keeping 71873 word types\n",
      "2021-02-24 00:03:41,339 : INFO : PROGRESS: at sentence #480000, processed 11641081 words, keeping 72449 word types\n",
      "2021-02-24 00:03:41,409 : INFO : PROGRESS: at sentence #490000, processed 11879460 words, keeping 73023 word types\n",
      "2021-02-24 00:03:41,484 : INFO : PROGRESS: at sentence #500000, processed 12122776 words, keeping 73581 word types\n",
      "2021-02-24 00:03:41,556 : INFO : PROGRESS: at sentence #510000, processed 12367121 words, keeping 74255 word types\n",
      "2021-02-24 00:03:41,627 : INFO : PROGRESS: at sentence #520000, processed 12607611 words, keeping 74782 word types\n",
      "2021-02-24 00:03:41,697 : INFO : PROGRESS: at sentence #530000, processed 12851530 words, keeping 75319 word types\n",
      "2021-02-24 00:03:41,768 : INFO : PROGRESS: at sentence #540000, processed 13089923 words, keeping 75959 word types\n",
      "2021-02-24 00:03:41,838 : INFO : PROGRESS: at sentence #550000, processed 13327324 words, keeping 76489 word types\n",
      "2021-02-24 00:03:41,912 : INFO : PROGRESS: at sentence #560000, processed 13575962 words, keeping 77031 word types\n",
      "2021-02-24 00:03:41,982 : INFO : PROGRESS: at sentence #570000, processed 13817112 words, keeping 77602 word types\n",
      "2021-02-24 00:03:42,052 : INFO : PROGRESS: at sentence #580000, processed 14052857 words, keeping 78189 word types\n",
      "2021-02-24 00:03:42,133 : INFO : PROGRESS: at sentence #590000, processed 14300517 words, keeping 78737 word types\n",
      "2021-02-24 00:03:42,205 : INFO : PROGRESS: at sentence #600000, processed 14545068 words, keeping 79300 word types\n",
      "2021-02-24 00:03:42,280 : INFO : PROGRESS: at sentence #610000, processed 14792482 words, keeping 79812 word types\n",
      "2021-02-24 00:03:42,350 : INFO : PROGRESS: at sentence #620000, processed 15030477 words, keeping 80319 word types\n",
      "2021-02-24 00:03:42,418 : INFO : PROGRESS: at sentence #630000, processed 15269440 words, keeping 80955 word types\n",
      "2021-02-24 00:03:42,454 : INFO : collected 81218 word types from a corpus of 15387847 raw words and 634862 sentences\n",
      "2021-02-24 00:03:42,455 : INFO : Loading a fresh vocabulary\n",
      "2021-02-24 00:03:42,506 : INFO : effective_min_count=5 retains 32596 unique words (40% of original 81218, drops 48622)\n",
      "2021-02-24 00:03:42,507 : INFO : effective_min_count=5 leaves 15306026 word corpus (99% of original 15387847, drops 81821)\n",
      "2021-02-24 00:03:42,585 : INFO : deleting the raw counts dictionary of 81218 items\n",
      "2021-02-24 00:03:42,588 : INFO : sample=0.001 downsamples 37 most-common words\n",
      "2021-02-24 00:03:42,589 : INFO : downsampling leaves estimated 11075722 word corpus (72.4% of prior 15306026)\n",
      "2021-02-24 00:03:42,613 : INFO : constructing a huffman tree from 32596 words\n",
      "2021-02-24 00:03:43,348 : INFO : built huffman tree with maximum node depth 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:03:43,717 : INFO : estimated required memory for 32596 words, 138020 buckets and 100 dimensions: 125922344 bytes\n",
      "2021-02-24 00:03:43,721 : INFO : resetting layer weights\n",
      "2021-02-24 00:03:47,289 : INFO : training model with 12 workers on 32596 vocabulary and 100 features, using sg=1 hs=1 sample=0.001 negative=5 window=5\n",
      "2021-02-24 00:04:39,906 : INFO : EPOCH 1 - PROGRESS: at 8.34% words, 17576 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:04:39,907 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:04:39,960 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:04:40,162 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:04:40,427 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:04:41,035 : INFO : EPOCH 1 - PROGRESS: at 41.68% words, 86009 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:04:41,037 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:04:41,078 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:04:41,522 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:04:41,564 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:04:41,701 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:04:41,741 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:04:41,751 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:04:41,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:04:41,819 : INFO : EPOCH - 1 : training on 15394371 raw words (11081995 effective words) took 54.5s, 203412 effective words/s\n",
      "2021-02-24 00:05:33,596 : INFO : EPOCH 2 - PROGRESS: at 8.33% words, 17853 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:05:33,597 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:05:33,762 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:05:34,042 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:05:34,087 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:05:34,601 : INFO : EPOCH 2 - PROGRESS: at 41.68% words, 87573 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:05:34,603 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:05:34,783 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:05:34,868 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:05:34,923 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:05:35,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:05:35,350 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:05:35,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:05:35,492 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:05:35,497 : INFO : EPOCH - 2 : training on 15394371 raw words (11079956 effective words) took 53.6s, 206617 effective words/s\n",
      "2021-02-24 00:06:27,185 : INFO : EPOCH 3 - PROGRESS: at 8.34% words, 17898 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:06:27,187 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:06:27,262 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:06:27,326 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:06:27,615 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:06:28,202 : INFO : EPOCH 3 - PROGRESS: at 41.68% words, 87669 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:06:28,203 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:06:28,329 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:06:28,361 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:06:28,364 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:06:28,779 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:06:28,860 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:06:28,894 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:06:29,046 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:06:29,047 : INFO : EPOCH - 3 : training on 15394371 raw words (11081885 effective words) took 53.5s, 207141 effective words/s\n",
      "2021-02-24 00:07:21,151 : INFO : EPOCH 4 - PROGRESS: at 8.34% words, 17748 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:07:21,153 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:07:21,438 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:07:21,548 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:07:21,590 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:07:22,364 : INFO : EPOCH 4 - PROGRESS: at 41.69% words, 86679 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:07:22,366 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:07:22,395 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:07:22,464 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:07:22,563 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:07:23,020 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:07:23,023 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:07:23,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:07:23,157 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:07:23,162 : INFO : EPOCH - 4 : training on 15394371 raw words (11081172 effective words) took 54.1s, 204961 effective words/s\n",
      "2021-02-24 00:08:15,260 : INFO : EPOCH 5 - PROGRESS: at 8.34% words, 17723 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:08:15,261 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2021-02-24 00:08:15,278 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2021-02-24 00:08:15,502 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2021-02-24 00:08:15,754 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2021-02-24 00:08:16,179 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-02-24 00:08:16,290 : INFO : EPOCH 5 - PROGRESS: at 50.03% words, 104377 words/s, in_qsize -1, out_qsize 1\n",
      "2021-02-24 00:08:16,291 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-02-24 00:08:16,378 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-02-24 00:08:16,480 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-02-24 00:08:16,628 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 00:08:16,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 00:08:16,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 00:08:16,813 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 00:08:16,814 : INFO : EPOCH - 5 : training on 15394371 raw words (11080062 effective words) took 53.6s, 206701 effective words/s\n",
      "2021-02-24 00:08:16,817 : INFO : training on a 76971855 raw words (55405070 effective words) took 269.5s, 205563 effective words/s\n",
      "2021-02-24 00:08:16,818 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2021-02-24 00:08:18,355 : INFO : saving FastText object under dados/experimento_1/ftt_jur.model, separately None\n",
      "2021-02-24 00:08:18,356 : INFO : storing np array 'vectors_ngrams' to dados/experimento_1/ftt_jur.model.wv.vectors_ngrams.npy\n",
      "2021-02-24 00:08:25,072 : INFO : not storing attribute vectors_norm\n",
      "2021-02-24 00:08:25,073 : INFO : not storing attribute vectors_vocab_norm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:08:25,074 : INFO : not storing attribute vectors_ngrams_norm\n",
      "2021-02-24 00:08:25,075 : INFO : not storing attribute buckets_word\n",
      "2021-02-24 00:08:25,076 : INFO : storing np array 'vectors_ngrams_lockf' to dados/experimento_1/ftt_jur.model.trainables.vectors_ngrams_lockf.npy\n",
      "2021-02-24 00:08:32,801 : INFO : saved dados/experimento_1/ftt_jur.model\n"
     ]
    }
   ],
   "source": [
    "ftt_jur = grouper.treinar_fasttext('dados/experimento_'+str(exp)+'/base_treino.txt', exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:12:50,826 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-02-24 00:12:50,828 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando modelo glove\n",
      "mkdir -p build\n",
      "tokenizando corpus\n",
      "$ build/vocab_count -min-count 5 -verbose 2 < ../mestrado/experimentos_mestrado/dados/experimento_1/base_treino_glv.txt > ../mestrado/experimentos_mestrado/dados/experimento_1/glove_vocab.txt\n",
      "criando matriz de coocorrencia\n",
      "$ build/cooccur -memory 4.0 -vocab-file ../mestrado/experimentos_mestrado/dados/experimento_1/glove_vocab.txt -verbose 2 -window-size 15 < ../mestrado/experimentos_mestrado/dados/experimento_1/base_treino_glv.txt > ../mestrado/experimentos_mestrado/dados/experimento_1/glv_concurrence.bin\n",
      "$ build/shuffle -memory 4.0 -verbose 2 < ../mestrado/experimentos_mestrado/dados/experimento_1/glv_concurrence.bin > ../mestrado/experimentos_mestrado/dados/experimento_1/glv_concurrence_shuf.bin\n",
      "$ build/glove -save-file ../mestrado/experimentos_mestrado/dados/experimento_1/glv_jur -threads 8 -input-file ../mestrado/experimentos_mestrado/dados/experimento_1/glv_concurrence_shuf.bin -x-max 10 -iter 15 -vector-size 100 -binary 2 -vocab-file ../mestrado/experimentos_mestrado/dados/experimento_1/glove_vocab.txt -verbose 2\n",
      "\n",
      "BUILDING VOCABULARY\n",
      "Processed 0 tokens.100000 tokens.200000 tokens.300000 tokens.400000 tokens.500000 tokens.600000 tokens.700000 tokens.800000 tokens.900000 tokens.1000000 tokens.1100000 tokens.1200000 tokens.1300000 tokens.1400000 tokens.1500000 tokens.1600000 tokens.1700000 tokens.1800000 tokens.1900000 tokens.2000000 tokens.2100000 tokens.2200000 tokens.2300000 tokens.2400000 tokens.2500000 tokens.2600000 tokens.2700000 tokens.2800000 tokens.2900000 tokens.3000000 tokens.3100000 tokens.3200000 tokens.3300000 tokens.3400000 tokens.3500000 tokens.3600000 tokens.3700000 tokens.3800000 tokens.3900000 tokens.4000000 tokens.4100000 tokens.4200000 tokens.4300000 tokens.4400000 tokens.4500000 tokens.4600000 tokens.4700000 tokens.4800000 tokens.4900000 tokens.5000000 tokens.5100000 tokens.5200000 tokens.5300000 tokens.5400000 tokens.5500000 tokens.5600000 tokens.5700000 tokens.5800000 tokens.5900000 tokens.6000000 tokens.6100000 tokens.6200000 tokens.6300000 tokens.6400000 tokens.6500000 tokens.6600000 tokens.6700000 tokens.6800000 tokens.6900000 tokens.7000000 tokens.7100000 tokens.7200000 tokens.7300000 tokens.7400000 tokens.7500000 tokens.7600000 tokens.7700000 tokens.7800000 tokens.7900000 tokens.8000000 tokens.8100000 tokens.8200000 tokens.8300000 tokens.8400000 tokens.8500000 tokens.8600000 tokens.8700000 tokens.8800000 tokens.8900000 tokens.9000000 tokens.9100000 tokens.9200000 tokens.9300000 tokens.9400000 tokens.9500000 tokens.9600000 tokens.Processed 9684898 tokens.\n",
      "Counted 81039 unique words.\n",
      "Truncating vocabulary at min count 5.\n",
      "Using vocabulary of size 32431.\n",
      "\n",
      "COUNTING COOCCURRENCES\n",
      "window size: 15\n",
      "context: symmetric\n",
      "max product: 13752509\n",
      "overflow length: 38028356\n",
      "Reading vocab from file \"../mestrado/experimentos_mestrado/dados/experimento_1/glove_vocab.txt\"...loaded 32431 words.\n",
      "Building lookup table...table contains 73365265 elements.\n",
      "Processing token: 0100000200000300000400000500000600000700000800000900000100000011000001200000130000014000001500000160000017000001800000190000020000002100000220000023000002400000250000026000002700000280000029000003000000310000032000003300000340000035000003600000370000038000003900000400000041000004200000430000044000004500000460000047000004800000490000050000005100000520000053000005400000550000056000005700000580000059000006000000610000062000006300000640000065000006600000670000068000006900000700000071000007200000730000074000007500000760000077000007800000790000080000008100000820000083000008400000850000086000008700000880000089000009000000910000092000009300000940000095000009600000Processed 9684898 tokens.\n",
      "Writing cooccurrences to disk........2 files in total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging cooccurrence files: processed 0 lines.100000 lines.200000 lines.300000 lines.400000 lines.500000 lines.600000 lines.700000 lines.800000 lines.900000 lines.1000000 lines.1100000 lines.1200000 lines.1300000 lines.1400000 lines.1500000 lines.1600000 lines.1700000 lines.1800000 lines.1900000 lines.2000000 lines.2100000 lines.2200000 lines.2300000 lines.2400000 lines.2500000 lines.2600000 lines.2700000 lines.2800000 lines.2900000 lines.3000000 lines.3100000 lines.3200000 lines.3300000 lines.3400000 lines.3500000 lines.3600000 lines.3700000 lines.3800000 lines.3900000 lines.4000000 lines.4100000 lines.4200000 lines.4300000 lines.4400000 lines.4500000 lines.4600000 lines.4700000 lines.4800000 lines.4900000 lines.5000000 lines.5100000 lines.5200000 lines.5300000 lines.5400000 lines.5500000 lines.5600000 lines.5700000 lines.5800000 lines.5900000 lines.6000000 lines.6100000 lines.6200000 lines.6300000 lines.6400000 lines.6500000 lines.6600000 lines.6700000 lines.6800000 lines.6900000 lines.7000000 lines.7100000 lines.7200000 lines.7300000 lines.7400000 lines.7500000 lines.7600000 lines.7700000 lines.7800000 lines.7900000 lines.8000000 lines.8100000 lines.8200000 lines.8300000 lines.8400000 lines.8500000 lines.8600000 lines.8700000 lines.8800000 lines.8900000 lines.9000000 lines.9100000 lines.9200000 lines.9300000 lines.9400000 lines.9500000 lines.9600000 lines.9700000 lines.9800000 lines.9900000 lines.10000000 lines.10100000 lines.10200000 lines.10300000 lines.10400000 lines.10500000 lines.10600000 lines.10700000 lines.10800000 lines.10900000 lines.11000000 lines.11100000 lines.11200000 lines.11300000 lines.11400000 lines.11500000 lines.11600000 lines.11700000 lines.11800000 lines.11900000 lines.12000000 lines.12100000 lines.12200000 lines.12300000 lines.12400000 lines.12500000 lines.12600000 lines.12700000 lines.12800000 lines.12900000 lines.13000000 lines.13100000 lines.13200000 lines.13300000 lines.13400000 lines.13500000 lines.13600000 lines.13700000 lines.13800000 lines.13900000 lines.14000000 lines.14100000 lines.14200000 lines.14300000 lines.14400000 lines.14500000 lines.14600000 lines.14700000 lines.14800000 lines.14900000 lines.15000000 lines.15100000 lines.15200000 lines.15300000 lines.15400000 lines.15500000 lines.15600000 lines.15700000 lines.15800000 lines.15900000 lines.16000000 lines.16100000 lines.16200000 lines.16300000 lines.16400000 lines.16500000 lines.16600000 lines.16700000 lines.16800000 lines.16900000 lines.17000000 lines.17100000 lines.17200000 lines.17300000 lines.17400000 lines.17500000 lines.17600000 lines.17700000 lines.17800000 lines.17900000 lines.18000000 lines.18100000 lines.18200000 lines.18300000 lines.18400000 lines.18500000 lines.18600000 lines.18700000 lines.18800000 lines.18900000 lines.19000000 lines.19100000 lines.19200000 lines.19300000 lines.19400000 lines.19500000 lines.19600000 lines.19700000 lines.19800000 lines.19900000 lines.20000000 lines.20100000 lines.20200000 lines.20300000 lines.20400000 lines.20500000 lines.20600000 lines.20700000 lines.20800000 lines.20900000 lines.21000000 lines.21100000 lines.21200000 lines.21300000 lines.21400000 lines.21500000 lines.21600000 lines.21700000 lines.21800000 lines.21900000 lines.22000000 lines.22100000 lines.22200000 lines.22300000 lines.22400000 lines.22500000 lines.22600000 lines.22700000 lines.22800000 lines.22900000 lines.23000000 lines.23100000 lines.23200000 lines.23300000 lines.23400000 lines.23500000 lines.23600000 lines.23700000 lines.23800000 lines.23900000 lines.24000000 lines.24100000 lines.24200000 lines.24300000 lines.24400000 lines.24500000 lines.24600000 lines.24700000 lines.24800000 lines.24900000 lines.25000000 lines.25100000 lines.25200000 lines.25300000 lines.25400000 lines.25500000 lines.25600000 lines.25700000 lines.25800000 lines.25900000 lines.26000000 lines.26100000 lines.26200000 lines.26300000 lines.26400000 lines.26500000 lines.26600000 lines.26700000 lines.26800000 lines.26900000 lines.27000000 lines.27100000 lines.27200000 lines.27300000 lines.27400000 lines.27500000 lines.27600000 lines.27700000 lines.27800000 lines.27900000 lines.28000000 lines.28100000 lines.28200000 lines.28300000 lines.28400000 lines.28500000 lines.28600000 lines.28700000 lines.28800000 lines.28900000 lines.29000000 lines.29100000 lines.29200000 lines.29300000 lines.29400000 lines.29500000 lines.29600000 lines.29700000 lines.29800000 lines.29900000 lines.30000000 lines.30100000 lines.30200000 lines.30300000 lines.30400000 lines.30500000 lines.30600000 lines.30700000 lines.30800000 lines.30900000 lines.31000000 lines.31100000 lines.31200000 lines.31300000 lines.31400000 lines.31500000 lines.31600000 lines.Merging cooccurrence files: processed 31681021 lines.\n",
      "\n",
      "Using random seed 1614136387\n",
      "SHUFFLING COOCCURRENCES\n",
      "array size: 255013683\n",
      "Shuffling by chunks: processed 0 lines.processed 31681021 lines.\n",
      "Wrote 1 temporary file(s).\n",
      "Merging temp files: processed 0 lines.31681021 lines.Merging temp files: processed 31681021 lines.\n",
      "\n",
      "TRAINING MODEL\n",
      "Read 31681021 lines.\n",
      "Initializing parameters...Using random seed 1614136398\n",
      "done.\n",
      "vector size: 100\n",
      "vocab size: 32431\n",
      "x_max: 10.000000\n",
      "alpha: 0.750000\n",
      "02/24/21 - 12:13.30AM, iter: 001, cost: 0.108892\n",
      "02/24/21 - 12:13.42AM, iter: 002, cost: 0.079047\n",
      "02/24/21 - 12:13.53AM, iter: 003, cost: 0.066208\n",
      "02/24/21 - 12:14.04AM, iter: 004, cost: 0.058593\n",
      "02/24/21 - 12:14.15AM, iter: 005, cost: 0.054242\n",
      "02/24/21 - 12:14.26AM, iter: 006, cost: 0.051647\n",
      "02/24/21 - 12:14.37AM, iter: 007, cost: 0.049941\n",
      "02/24/21 - 12:14.48AM, iter: 008, cost: 0.048715\n",
      "02/24/21 - 12:14.59AM, iter: 009, cost: 0.047794\n",
      "02/24/21 - 12:15.10AM, iter: 010, cost: 0.047077\n",
      "02/24/21 - 12:15.21AM, iter: 011, cost: 0.046466\n",
      "02/24/21 - 12:15.32AM, iter: 012, cost: 0.045977\n",
      "02/24/21 - 12:15.43AM, iter: 013, cost: 0.045560\n",
      "02/24/21 - 12:15.54AM, iter: 014, cost: 0.045182\n",
      "02/24/21 - 12:16.05AM, iter: 015, cost: 0.044861\n",
      "\n",
      "treinamento concluído\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 00:16:06,923 : INFO : converting 32432 vectors from dados/experimento_1/glv_jur.txt to C:\\Users\\CRISTI~1\\AppData\\Local\\Temp\\test_word2vec.txt\n",
      "2021-02-24 00:16:07,006 : INFO : loading projection weights from C:\\Users\\CRISTI~1\\AppData\\Local\\Temp\\test_word2vec.txt\n",
      "2021-02-24 00:16:09,851 : INFO : loaded (32432, 100) matrix from C:\\Users\\CRISTI~1\\AppData\\Local\\Temp\\test_word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "glv_jur = grouper.treinar_glove(exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
